{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraper set for https://uk.trustpilot.com/review/www.johnlewis.com - saving result to trust_reviews.csv\n"
     ]
    }
   ],
   "source": [
    "## Configurations\n",
    "\n",
    "# Trustpilot review page\n",
    "url = 'https://uk.trustpilot.com/review/www.johnlewis.com'\n",
    "\n",
    "# Data file to save to\n",
    "final_list=[]#final list to be the df\n",
    "save_datafile = 'trust_reviews.csv'\n",
    "\n",
    "# Trustpilot default \n",
    "results_per_page = 20 \n",
    "total_pages = 1\n",
    "\n",
    "print('Scraper set for ' + url + ' - saving result to ' + save_datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found total of 485 pages to scrape\n"
     ]
    }
   ],
   "source": [
    "## Count amount of pages to scrape\n",
    "\n",
    "# Get page\n",
    "r=requests.get(url)\n",
    "soup = BeautifulSoup(r.text, 'lxml')\n",
    "\n",
    "# Total amount of ratings\n",
    "rating_count = soup.find('span',class_='headline__review-count')\n",
    "rating_count = int(rating_count.text.replace(',',''))\n",
    "\n",
    "# Throttling to avoid spamming page with requests\n",
    "# With sleepTime seconds between every page request\n",
    "throttle = False\n",
    "sleep_time = 2\n",
    "\n",
    "# Total pages to scrape\n",
    "total_pages = math.ceil(rating_count / results_per_page)\n",
    "\n",
    "print('Found total of ' + str(total_pages) + ' pages to scrape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Title  \\\n",
      "0     Unsatisfactory Customer Service from John Lewis   \n",
      "1              Be careful about using Click & Collect   \n",
      "2               I am still waiting to hear from John…   \n",
      "3          John Lewis Customer Service! doesn't exist   \n",
      "4   Warranty worse than useless…  on electronic go...   \n",
      "5        FOLLOW UP TO WARNING ABOUT APPROVED SUPPLIER   \n",
      "6                          Excellent customer service   \n",
      "7                              What Customer service!   \n",
      "8                       Excellent after sales service   \n",
      "9             Terrible customer service at Newcastle…   \n",
      "10                      Over promised under delivered   \n",
      "11                               Hi again John Lewis.   \n",
      "12                  Faulty television, refund refused   \n",
      "13                   Yet again JL let themselves down   \n",
      "14                      Made to feel like a criminal!   \n",
      "15                              Disappointing service   \n",
      "16                                   TERRIBLE SERVICE   \n",
      "17                                  Appalling service   \n",
      "18            Very poor solution of technicial issues   \n",
      "19                                 We love John Lewis   \n",
      "\n",
      "                                              Content        Date Rating  \n",
      "0   Last month I purchased a Micro Flex Deluxe sco...  2020-03-17      1  \n",
      "1   Be careful about using Click and Collect.  I o...  2020-03-17      1  \n",
      "2   I am still waiting to hear from John Lewis wit...  2020-03-17      2  \n",
      "3   What do you expect from Customer Service?Actio...  2020-03-17      1  \n",
      "4   So disappointed with John Lewis.  Had been hap...  2020-03-16      1  \n",
      "5   After seven days, seven agents and a mini tele...  2020-03-16      2  \n",
      "6   I bought a radio from the Ipswich John Lewis. ...  2020-03-16      5  \n",
      "7   Contacted main customer service line as I had ...  2020-03-16      1  \n",
      "8   Excellent after sales service. Staff is always...  2020-03-15      5  \n",
      "9   Terrible customer service at Newcastle upon Ty...  2020-03-15      5  \n",
      "10  Had to only give a review of 2, customer servi...  2020-03-15      2  \n",
      "11  Hi again John Lewis.I'm afraid I've yet anothe...  2020-03-15      1  \n",
      "12  Purchased a television 9 months ago which is n...  2020-03-14      1  \n",
      "13  Yet again JL let themselves down.  Tried to pl...  2020-03-14      1  \n",
      "14  I purchased a Ralph Lauren down jacket on 11 J...  2020-03-14      1  \n",
      "15  I am very disappointed with the service and wo...  2020-03-14      1  \n",
      "16  TERRIBLE SERVICE! To start I tried to reserve ...  2020-03-14      1  \n",
      "17  Appalling service -  JL was once a company tha...  2020-03-14      1  \n",
      "18  If there's negative mark, I would put negative...  2020-03-14      1  \n",
      "19  We love John Lewis - great quality and excelle...  2020-03-14      5  \n"
     ]
    }
   ],
   "source": [
    "## Run Scraper\n",
    "for pg in range(1, total_pages + 1):\n",
    "    pg = url + '?page=' + str(pg)\n",
    "    r=requests.get(pg)\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "        \n",
    "    for paragraph in soup.find_all('section',class_='review__content'):\n",
    "        title_section=paragraph.find('h2',class_='review-content__title')   \n",
    "        \n",
    "        if title_section:\n",
    "            title = title_section.find('a').text.strip()\n",
    "        else:\n",
    "            title = ''\n",
    "            \n",
    "        content=paragraph.find('p',class_='review-content__text')\n",
    "        \n",
    "        if content:\n",
    "            content = content.text.strip()\n",
    "            datedata= json.loads(paragraph.find('div',class_='review-content-header__dates').text)\n",
    "            date=datedata['publishedDate'].split('T')[0]\n",
    "            rating_class=paragraph.find('div',class_='star-rating')\n",
    "\n",
    "            rating=rating_class.find('img')['alt'][0]   \n",
    "\n",
    "            final_list.append([title,content,date,rating])\n",
    "\n",
    "    if(throttle): \n",
    "        time.sleep(sleep_time)\n",
    "        \n",
    "df = pd.DataFrame(final_list,columns=['Title','Content','Date','Rating'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save dataframe to csv\n",
    "df.to_csv(save_datafile, encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('p37': conda)",
   "language": "python",
   "name": "python37564bitp37conda2b1eeea87ee044609be89b011a3e6682"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
